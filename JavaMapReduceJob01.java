package ucsc.hadoop.homework2;

import java.io.File;
import java.io.IOException;
import java.util.ArrayList;

import org.apache.commons.io.FileUtils;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;
import ucsc.hadoop.util.ConfigurationUtil;

/**
 * MapReduce application to compile a list of all the actors that were cast in each movie.
 * 
 * The output is sorted by movie title, in ascending lexicographic order.
 * 
 * Each output record consists of a movie title, followed by a list of actor names.
 * 
 * The list of actor names is delimited with square brackets, and each actor name in the list is delimited with
 * square brackets. Each actor name (except the last) is followed by a comma and a space for readability.
 * Example:
 * 
 * MovieNameOne [[ActorOne]]
 * MovieNameTwo [[ActorOne], [ActorTwo]]
 * ...
 * 
 *********************************************************************************************************** 
 * Use my saved Java launch configuration to run this application:                                         * 
 * ${workspace_loc:RonaldInselbergHadoopAssignmentTwo}/ListActorsForEachMovie.launch                       * 
 *                                                                                                         * 
 * The output of the MapReduce job goes to:                                                                * 
 * ${workspace_loc:RonaldInselbergHadoopAssignmentTwo}/output/PartOne/part-r-00000                         * 
 *                                                                                                         *  
 * The next to last step copies the output of the MapReduce job to:                                        * 
 * ${workspace_loc:RonaldInselbergHadoopAssignmentTwo}/OutputDataForPartOne                                *
 *                                                                                                         *  
 * The last step deletes the intermediate data that was generated by the MapReduce job.                    *
 *                                                                                                         * 
 * After the application has run to completion, access the output data file by selecting                   *
 * RonaldInselbergHadoopAssignmentTwo and Refresh to make OutputDataForPartOne visible in the              *
 * Project Explorer window. Open OutputDataForPartOne with a text editor to see the output data.           *   
 *                                                                                                         * 
 ***********************************************************************************************************
 * 
 * ListActorsForEachMovie requires a single Java launch configuration argument to specify the
 * movies database input file:
 * 
 *     ${workspace_loc:RonaldInselbergHadoopAssignmentTwo}/data/movie/imdb.tsv
 * 
 * The MapReduce output data is copied and saved in:
 * 
 *     ${workspace_loc:RonaldInselbergHadoopAssignmentTwo}/OutputDataForPartOne
 * 
 * The number of reducers is set to one (1) to produce a single output file
 * that has all of the transformed data. The number of mappers is unconstrained.
 * 
 * The program has only been tested in Hadoop local mode.
 * 
 * @author Ronald Inselberg
 *
 */
public class ListActorsForEachMovie extends Configured implements Tool {
  
	private static final Log LOG = LogFactory.getLog(ListActorsForEachMovie.class);
	
	/*
	 * Designate a Hadoop MapReduce data directory
	 */
	private static final String job1OutputDirectoryName = "output/PartOne";
	
	/*
	 * Designate a destination file for the final output data.
	 * The file will either be created, or overwritten if it already exists.
	 */
	private static final String finalOutputDestinationFileName = "OutputDataForPartOne";
	
	public int run(String[] args) throws Exception {
		Configuration conf = getConf();
		if (args.length != 1) {
			System.err.println("Usage: moviecount <in>");
			System.exit(2);
		}
		
		/**
		 * Deletes Hadoop MapReduce data directory if it already exists.
		 * Otherwise Hadoop fails with a file system exception.
		 */
		File outputDirectory = new File("job1OutputDirectoryName");
		if (outputDirectory.exists()) {
			try {
				FileUtils.deleteDirectory(outputDirectory);
			} catch (IOException e) {
				System.err.println(e);
				throw new IllegalArgumentException("Unable to delete " + outputDirectory + " Is it write protected?");
			}
		}
		
		if (outputDirectory.exists()) {
			System.out.println("This should never happen, but if it happens anyway, please select /RonaldInselbergHadoopAssignmentTwo/output/PartOne");
			System.out.println("in Project Explorer and Delete, then select ListActorsForEachMovie.launch and run again.");
			System.exit(99);
		}
		
		ConfigurationUtil.dumpConfigurations(conf, System.out);
		
		LOG.info("input: " + args[0] + " output: " + job1OutputDirectoryName);
		
		Job job = new Job(conf, "MapReduce job1");
		job.setJarByClass(ListActorsForEachMovie.class);
		job.setMapperClass(MovieTokenizerMapper.class);
		job.setNumReduceTasks(1);	//write a single output file with all of the transformed data
		job.setReducerClass(ActorsListReducer.class);

		job.setMapOutputKeyClass(Text.class);
		job.setMapOutputValueClass(Text.class);
		
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(ArrayList.class);
		
		FileInputFormat.addInputPath(job, new Path(args[0]));
		FileOutputFormat.setOutputPath(job, new Path(job1OutputDirectoryName));
		
		boolean result = job.waitForCompletion(true);
		return (result) ? 0 : 1;
	}
	
	public static void main(String[] args) throws Exception {
		int exitCode = ToolRunner.run(new ListActorsForEachMovie(), args);
		
		// copy output data from MapReduce job to final output destination file
		File finalOutputDestination = new File(finalOutputDestinationFileName);
		if (exitCode==0) {
			try {
				File outputFromMapReduceJob = new File(job1OutputDirectoryName + "/part-r-00000");
				FileUtils.copyFile(outputFromMapReduceJob, finalOutputDestination);
			} catch (IOException e) {
				System.err.println(e);
				System.err.println("IOexception, unable to copy Job #1 output data to final output destination file");
				System.exit(1);
			}
		}
		System.out.println("output file is " + finalOutputDestination);
		System.out.println("select RonaldInselbergHadoopAssignmentTwo and Refresh to display " + finalOutputDestination + " in Project Explorer");
		System.out.println("open " + finalOutputDestination + " with a text editor to see the output data");
		
		// delete MapReduce diretories and data files
		File outputDirectory = new File(job1OutputDirectoryName);
		if (outputDirectory.exists()) {
			try {
				FileUtils.deleteDirectory(outputDirectory);
			} catch (IOException e) {
				System.err.println(e);
				System.err.println("unable to delete MapReduce data directories and files created by Hadoop");
				System.exit(1);
			}
		}
		// clean up and exit
		System.out.println("main has completed with exitCode " + exitCode);
		System.exit(exitCode);

	}
	
	public static class MovieTokenizerMapper extends Mapper<Object, Text, Text, Text> {
		private static Text movieTitle = new Text();
		private static Text actorName = new Text();

		
		@Override
		public void map(Object key, Text value, Context context) 
				throws IOException, InterruptedException {
			String[] tokens = value.toString().split("\\t");
			
			if (tokens.length == 3) {
				actorName.set(tokens[0]);
				movieTitle.set(tokens[1]);
				context.write(movieTitle, actorName);
			}
		}
	}
	
	public static class ActorsListReducer extends Reducer<Text, Text, Text, ArrayList<String>> {
		
		@Override
		public void reduce(Text movieTitle, Iterable<Text> actorNames, Context context) 
				 throws IOException, InterruptedException {
			
			ArrayList<String> listOfActors = new ArrayList<String>();
			for (Text name : actorNames) {
				listOfActors.add("[" + name.toString() + "]");
			}
			context.write(movieTitle, listOfActors);
		}
	}
	
}
